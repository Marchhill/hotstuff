% Principally, this chapter should describe the work which was undertaken before code was written, hardware built or theories worked on. It should show how the project proposal was further refined and clarified, so that the implementation stage could go smoothly rather than by trial and error.

% Throughout this chapter and indeed the whole dissertation, it is essential to demonstrate that a proper professional approach was employed.

% The nature of this chapter will vary greatly from one dissertation to another but, underlining the professional approach, this chapter will very likely include a section headed "Requirements Analysis" and refer to appropriate software engineering techniques used in the dissertation. The chapter will also cite any new programming languages and systems which had to be learnt and will mention complicated theories or algorithms which required understanding.

% It is essential to declare the starting point. This states any existing codebase or materials that your project builds on. The text here can commonly be identical to the text in your proposal, but it may enlarge on it or report variations. For instance, the true starting point may have turned out to be different from that declared in the proposal and such discrepancies must be explained.

\textit{In this chapter we disclose my knowledge and experience prior to beginning this project (Section \ref{start}), give a theoretical basis for understanding the HotStuff algorithm by building up from simpler consensus algorithms (Section \ref{hotstufftheory}), outline the tools, libraries (Section \ref{tools}), and professional methodology (Section \ref{softwareeng}) deployed in implementation, and highlight the requirements that the implementation should meet (Section \ref{requirements}).}

\section{Starting point} \label{start}
I had some experience using OCaml from the IA Foundations of Computer Science course but had never used it in a project. The IB Distributed Systems course also provided some useful background knowledge, particularly as it briefly covered Raft \cite{ongaroSearchUnderstandableConsensus2014}, a non-byzantine consensus algorithm. I had some understanding of byzantine consensus from my own reading into Nakamoto consensus \cite{nakamotoBitcoinPeertoPeerElectronic2008} and from developing a wallet application for Ethereum \cite{ethereumWhite, ethereumYellow}; neither of these was directly useful to implementing HotStuff, but they gave me some wider context of the field.

\section{HotStuff algorithm} \label{hotstufftheory}
HotStuff is a byzantine consensus algorithm; it allows a group of nodes to reach consensus on a log of values under adverse conditions, such as messages being lost, or some nodes being byzantine. In each \textit{view} a \textit{leader} node proposes some value by sending it the \textit{replicas} (another word for nodes). After several messages are exchanged the log may be committed, meaning that there is consensus on the committed part of the log, and it is now immutable.

The system model describes the adverse conditions under which HotStuff can operate:
\begin{assumption}[Partially Synchronous] \label{partialsyncassumption}
	Messages sent by one party will always be delivered to another within some bounded amount of time ($\Delta$) after global synchronisation time (GST) has been reached \cite{dworkConsensusPresencePartial1988}.
\end{assumption}

\begin{assumption}[Authenticated] \label{authassumption}
	We assume that all messages are signed, providing an authenticated channel where no messages can be spoofed.
\end{assumption}

\begin{assumption}[Byzantine] \label{byzassumption}
	A maximum of $f$ faulty nodes may be controlled by an adversary that is actively trying to prevent the nodes from reaching consensus, where $n = 3f + 1$ and $n$ is the total number of nodes
\end{assumption}

Assumptions \ref{partialsyncassumption} and \ref{byzassumption} are the weakest possible assumptions under which it is possible to reach consensus \cite{peaseReachingAgreementPresence1980,fischerEasyImpossibilityProofs1986}. Assumption \ref{authassumption} is also needed, but byzantine consensus is possible without cryptographic signatures; there is an algorithm called Information Theoretic HotStuff, which does not use signatures, and is secure against a computationally unbounded adversary\footnote{An authenticated channel can be obtained without signatures by using one time pads or quantum cryptography \cite{bennettExperimentalQuantumCryptography1992}.} \cite{abrahamInformationTheoreticHotStuff2020}.

HotStuff has the following properties:

\begin{property}[Safety] \label{safetyproperty}
	Once some prefix of a log has been committed, that part of the log is immutable, it can only be appended to.
\end{property}

\begin{property}[Liveness] \label{livenessproperty}
	Assuming there is a functioning \textit{pacemaker}, the system is guaranteed to make progress within some bounded amount of time once GST has been reached and a non-faulty leader is chosen. The pacemaker ensures that all honest replicas will remain in some view with an honest leader for long enough to make progress (Section \ref{pacemaker}).
\end{property}

\begin{property}[Optimistic Responsiveness] \label{optresponsiveproperty}
	Once GST has been reached and a non-faulty leader is chosen, the system is able to make progress as fast as network conditions allow; it does not have to wait for some timeout to elapse \cite{passThunderellaBlockchainsOptimistic2018}.
\end{property}

Basic HotStuff is a responsive byzantine consensus algorithm (Section \ref{optresponsive}). We will start by describing a simpler consensus algorithm that is not responsive or byzantine (Section \ref{nonbyzconsensus}). We then extend this algorithm to handle byzantine threats (Section \ref{byzconsensus}). Finally, we extend this algorithm to be responsive by removing the need for a timeout to progress, arriving at the basic HotStuff algorithm (Section \ref{optresponsive}).

\subsection{Non-byzantine consensus} \label{nonbyzconsensus}
We will start by describing a generic algorithm to solve the simpler problem of reaching consensus with the stronger assumption of a crash-stop model instead of a byzantine one; this means that we assume nodes cannot be malicious but they can still crash and never come back online. Examples of similar algorithms include Raft \cite{ongaroSearchUnderstandableConsensus2014} and MultiPaxos \cite{lamportParttimeParliament1998, lamportPaxosMadeSimple2001}.

Each view is composed of several \textit{phases}. In each phase, the leader broadcasts to the replicas, that respond with an acknowledgement (\textit{ack}). The leader waits until it receives a \textit{quorum} of acks before proceeding to the next phase; for this algorithm, a quorum consists of $\frac{n}{2}$ acks.

The final phase of a consensus algorithm is \textit{decide}, it commences once the log is committed. This phase assumes that consensus is being used in the context of state machine replication \cite{lamportTimeClocksOrdering1978,schneiderImplementingFaulttolerantServices1990}: a \textit{client} sends commands to the nodes, the nodes reach consensus on a log of commands, and then execute them in order, ensuring that all nodes will be in the same state. In the \textit{decide} phase, the nodes can execute the new commands and respond to the client that the command was successfully committed.

In this generic algorithm, each view consists of three phases:

\begin{description}
	\item \textit{new-view} --- the leader learns about previously committed logs. All replicas send a \textit{new-view} message to the leader, containing their longest previously committed log.
	\item \textit{commit} --- the leader waits until it receives a quorum of greater than $\frac{n}{2}$ \textit{new-view} messages, and then picks the longest log it received ($\lambda$) to propose. It then broadcasts a \textit{commit} message to the replicas, proposing $\lambda'$ to the nodes, where $\lambda'$ is $\lambda$ optionally extended with the leader's new value.
	\item \textit{decide} --- once the leader receives a quorum of acks, the log has been successfully committed. The leader can broadcast ``decide'' to the replicas, who can execute the new commands and respond to the client.
\end{description}

Crucially, this algorithm is safe (Property \ref{safetyproperty}). Since the leader waits to receive a quorum of greater than $\frac{n}{2}$ \textit{new-view} messages, $\lambda$ is guaranteed to be the longest log that has previously been committed. This is because the quorum of \textit{new-view} messages must share at least one node with the past quorum of \textit{commit} acks for $\lambda$. The new proposal $\lambda'$ will never conflict with $\lambda$, hence the algorithm is safe.

\subsection{Byzantine consensus} \label{byzconsensus}
In this section, we extend our non-byzantine algorithm (Section \ref{nonbyzconsensus}) to achieve consensus under a byzantine system model (assumption \ref{byzassumption}). To do this we must first introduce the \textit{quorum certificate} (\textit{QC}), a cryptographic proof that a leader has received a quorum of acks. We then consider the threats posed by byzantine nodes, give an algorithm that solves these problems, and make an argument for safety. Examples of similar algorithms include Tendermint \cite{kwonTendermintConsensusMining2014} and Casper \cite{buterinCasperFriendlyFinality2019}.

\subsubsection{Quorum certificates}

A QC is a quorum of $n - f$ acks with a matching \textit{threshold signature}. A threshold signature combines several signatures of the same message into one \cite{shoupPracticalThresholdSignatures2000, cachinRandomOraclesConstantinople2005}; in this case, the signature from each ack is combined\footnote{Recall that our messages are signed to provide authenticated delivery (assumption \ref{authassumption}).}. QCs have a key property that our byzantine algorithm will rely on:

\begin{property} \label{qcproperty}
There will always be at least one honest node in the intersection of any two QCs.
\end{property}

Recall that $n = 3f + 1$. The property holds since a QC contains a quorum of $n - f$ acks, at least $f + 1$ of which must be from honest nodes. To have two quorums that \textit{do not} share an honest node would require at least $2(f + 1) = 2f + 2$ honest nodes, but our system only has $2f + 1$.

\subsubsection{Threats introduced by byzantine nodes}
Byzantine nodes introduce two threats that we will deal with in turn. We present ideas for solutions to these threats; it will become clear why these solutions are effective in our argument that the algorithm is safe.

\begin{description}
\item \textit{Threat \#1 (Equivocation)} --- a faulty leader proposes one value to some replicas and a different value to others. For example, in the case of a cryptocurrency a malicious actor (Mallory) could carry out a double-spend attack by proposing ``Mallory transfers Alice £10" to some nodes and ``Mallory transfers Bob £10" to others, even if Mallory's account contains less than £20. \label{threat1}

To solve this add a new stage \textit{prepare} which happens just before the \textit{commit} phase, where the leader pre-proposes a log before proposing it in the \textit{commit} phase.

\item \textit{Threat \#2} --- a faulty leader proposes a log that conflicts with one that has previously been committed. \label{threat2}

To solve this make replicas \textit{lock} on a proposal once they receive a \textit{commit} message, and not accept a pre-proposal for a conflicting log.
\end{description}

\subsubsection{Byzantine fault-tolerant algorithm}
Modifying the non-byzantine algorithm (Section \ref{nonbyzconsensus}) to include our solutions to threats \ref{threat1} and \ref{threat2} results in the following:

\begin{description}
	\item \textit{new-view} --- \textit{same as the non-byzantine algorithm.}
	\item \textit{prepare} --- the leader waits $\Delta$ until it receives a \textit{new-view} message from all replicas (we will revisit this in Section \ref{optresponsive}), and then picks the longest log it received ($\lambda$) to pre-propose. It then broadcasts a \textit{prepare} message to the replicas, pre-proposing $\lambda'$ to the nodes, where $\lambda'$ is $\lambda$ optionally extended with the leader's new value. The replicas ensure that $\lambda'$ does not conflict with their \textit{lock} before sending an ack.
	\item \textit{commit} --- the leader waits until it receives a quorum of \textit{prepare} acks. It then broadcasts a \textit{commit} message to the replicas, proposing $\lambda'$ to the nodes, and includes a QC of \textit{prepare} acks. The replicas then \textit{lock} on $\lambda'$ and send a \textit{commit} ack.
	\item \textit{decide} --- \textit{same as the non-byzantine algorithm.}
\end{description}

\subsubsection{Argument for safety} \label{safetyargument}
We give an informal inductive argument that this algorithm is safe (Property \ref{safetyproperty}) based on it solving threats \ref{threat1} and \ref{threat2}. To be safe, we must have that if some log $\lambda$ is committed in view $v$, at no point in future will some conflicting log be committed.

Base case --- in view $v$, no log that conflicts with $\lambda$ may be committed; in other words, equivocation (Threat \ref{threat1}) is not possible. For a view to commit a value, there must have been a QC of \textit{prepare} acks, and a QC of \textit{commit} acks. By Property \ref{qcproperty}, there must be at least one honest replica in the intersection of these QCs that would not have acknowledged conflicting proposals in the same view.

Inductive step --- no conflicting log can be proposed in view $v'$ where $v' > v$ (Threat \ref{threat2}). This holds because any log pre-proposed in view $v'$ must receive a QC of \textit{prepare} acks; by property \ref{qcproperty}, there must be at least one honest node in the intersection between this QC, and the QC of \textit{commit} acks $\lambda$ in view $v$. This honest replica is locked on $\lambda$, so would not accept a proposal that conflicts with it.

From this, it follows that in no view from $v$ onwards will a log conflicting with $\lambda$ be committed, so the algorithm is safe.

\subsection{Optimistic responsiveness} \label{optresponsive}
In this section, we finally give the basic HotStuff algorithm by extending our generic byzantine consensus algorithm (section \ref{byzconsensus}) to make it optimistically responsive (Property \ref{optresponsiveproperty}). Optimistic responsiveness means that the system can make progress as fast as network conditions allow without waiting for a timeout, once GST has been reached \cite{passThunderellaBlockchainsOptimistic2018}.

The byzantine consensus algorithm is not responsive as it has a timeout in the \textit{prepare} phase. We first describe the problem that means this timeout is needed, then present an algorithm that solves it and make an informal argument that it does not break liveness.

\subsubsection{Why the timeout was necessary}
For the system to have liveness (Property \ref{livenessproperty}), the leader must wait for $\Delta$ to elapse so that it receives a \textit{new-view} message from \textit{all} honest replicas before it pre-proposes a log, to ensure that the pre-proposal will be voted for by the replicas. Consider what would happen if the leader did not wait for this timeout, and did not receive a \textit{new-view} from some honest replica $x$. It is possible that $x$ is locked on a longer log than the other replicas, as in some past view it received the \textit{commit} message, but other replicas did not\footnote{N.B. this means that the value was never actually committed, as this would have required a quorum of \textit{commit} acks}. When the leader sends the \textit{prepare} message, $x$ will not vote the pre-proposal as it is locked on a longer log, so the leader will not acquire a quorum of acks to make progress; this breaks liveness.

Solution idea --- add a \textit{pre-commit} phase directly before the \textit{commit} phase, where replicas store a \textit{key} for a proposal that they include in their \textit{new-view} message; this removes the need for a timeout, making the algorithm responsive.

\subsubsection{Basic HotStuff algorithm}

Modifying the byzantine algorithm (Section \ref{byzconsensus}) to include our solution idea leads to the following:

\begin{description}
	\item \textit{new-view} --- all replicas send their \textit{key} to the leader.
	\item \textit{prepare} ---  \textit{same as the byzantine algorithm, but picks the key for the longest log.}
	\item \textit{pre-commit} --- the leader waits until it receives a quorum of \textit{prepare} acks. It then broadcasts a \textit{pre-commit} message to the replicas, which contains a QC of \textit{prepare} acks. The replicas store this QC as a \textit{key} and send a \textit{pre-commit} ack.
	\item \textit{commit} --- \textit{same as the byzantine algorithm, but creates QC from pre-commit acks instead of prepare acks.}
	\item \textit{decide} --- \textit{same as the non-byzantine algorithm.}
\end{description}

\subsubsection{Argument for liveness} \label{livenessargument}
We informally argue for the liveness (Property \ref{livenessproperty}) of this algorithm. We first argue that the non-faulty leader will propose the longest log, and then that the honest replicas will vote for the proposal and progress will be made.

The non-faulty leader is guaranteed to receive a \textit{key} for the longest log ($\lambda^*$) that some honest replica is locked on. This is because for some replica to become locked on $\lambda^*$ there must be at least $f + 1$ honest nodes that have a \textit{key} for $\lambda^*$. The leader must hear about $\lambda^*$ from one of these honest nodes when it receives a quorum of \textit{new-view} messages and then propose it to the replicas.

The honest replicas will vote for the proposed log $\lambda^*$ as it does not conflict with their \textit{lock} and they are in the same view. The honest replicas are guaranteed to be synchronised in the same view by our assumption that there is a functioning pacemaker (Section \ref{pacemaker}). Furthermore, the replicas will progress through the other phases by our assumption that GST has been reached and messages must be delivered within $\Delta$.

\section{Tools \& libraries} \label{tools}
In this section, we outline the languages and libraries used in implementation and justify why they were appropriate for this project.

\subsection{OCaml}
I chose OCaml \cite{ocaml} for this project due to its high-level nature, static type system, ability to blend functional and imperative paradigms, powerful module system, and good library support. The performance bottlenecks for distributed byzantine algorithms are generally cryptography, message serialisation and network delays. This means that it is more important to choose a language with suitable features to aid implementation, rather than picking a `high-performance' language like C++.

OCaml's multi-paradigm nature is suitable for implementing HotStuff, as the core state machine can be elegantly expressed in a functional way, whereas interacting with the RPC library to send messages is better suited to an imperative paradigm.

OCaml has a powerful module system that facilitates writing highly reusable code that was only briefly touched upon in the tripos (in Concepts in Programming Languages from IB). A modular design allows key components such as the consensus algorithm to be easily reused in other projects.

\subsection{Lwt}
Lwt \cite{lwt} is a concurrent programming library for OCaml. It allows the creation of promises, which are values that will become determined in the future; these promises may spawn threads that perform computation and I/O in parallel. In order to use Lwt I had to learn about monads, which are ways of sequencing effects in functional languages that are used by promises in Lwt.

Lwt is useful to this project as promises provide a way to asynchronously dispatch messages over the network and wait for their responses in different threads. Promises are cheap to create in Lwt, so one can create many lightweight threads with good performance.

There are alternative libraries I could have used that may have had better performance, namely Jane Street's Async library \cite{async} and EIO \cite{eio}. I chose Lwt over these libraries due to superior documentation and stability.

\subsection{Cap'n Proto}
Cap'n Proto \cite{capnp} is an RPC framework that includes a library for sending and receiving RPCs, serialising messages, and a schema language for designing the format of RPCs that can be sent. Benchmarks for the library are presented in Section \ref{capnpbenchmark}.

\subsection{Tezos cryptography} \label{tezos}
The Tezos cryptography library \cite{tezosCrypto} provides aggregate signatures using the BLS12-381 elliptic curve construction. It provides functions to sign some data using a private key, aggregate several signatures into a single one, and check whether an aggregate signature is valid. Benchmarks for the library are presented in Section \ref{tezosbenchmark}.

The only difference from the threshold signatures needed by HotStuff is that each individual signature in an aggregate signature can sign different data, whereas with threshold signatures each individual signature is over the same data. It is trivial to implement threshold signatures using this library by checking that the data is the same for all signatures inside the aggregate signature.

\section{Requirements analysis} \label{requirements}

In order to be successful the implementation should conform to the following requirements:
\begin{itemize}
	\item Correctness --- the consensus algorithm should be implemented as it is described in the paper \cite{yinHotStuffBFTConsensus2019}. This can be established by testing the program trace for compliance with the algorithm specification.
	\item Evaluation --- analysis of system throughput and latency should be carried out by testing the program locally, analysing the trace, and testing in a simulated network.
	\item Optimisation --- implement features to improve transaction throughput and reduce latency over the naive implementation. This can be achieved through architectural decisions, tuning the scheduler, and ensuring cryptographic libraries are being used efficiently.
\end{itemize}

\section{Software engineering practices} \label{softwareeng}

In this section, we describe the professional software engineering methodology deployed during implementation and justify why this project is ethical.

\subsection{Development methodology} \label{devmethods}

For this project, we used an iterative waterfall development methodology. Objectives were chosen in accordance with the timetable set out in the proposal (Appendix \ref{proposal}). Development then proceeded in cycles of implementation, testing, and analysis of the program trace (to compare it to the protocol specification) and timing statements. This approach was particularly useful during the optimisation of our system (Section \ref{performance}), which required extensive analysis of the logs and rapid development of different prototypes to compare performance.

\subsection{Testing \& debugging methodology} \label{testing}

Unit testing was carried out using `expect tests', which compare a program trace to the correct output. A testing suite of expect tests verifies that the program behaves as specified in the HotStuff paper. This suite has 100\% code coverage\footnote{The report says 97.89\% coverage, but the only uncovered code is the testing code itself.} of the consensus state machine code, the coverage report is at \textit{\_coverage/index.html}.

The Memtrace library and viewer \cite{memtrace} were used to profile the memory usage of the program. One can generate a flame graph of memory allocations to see which parts of the program are using the most memory.

The Mininet virtual network \cite{mininet,lantzNetworkLaptopRapid2010} was used to test our system in a simulated wide area network (Section \ref{minineteval}).

The distributed nature of this project meant that debugging deadlocks and performance issues had to be carried out by manual inspection of the program trace and timing sections of the program. This is because the cause of these issues is often some process waiting or a backlog of work forming on some node, but this cannot be detected by normal debugging tools and profilers that track metrics like CPU usage.

\subsection{Source code management}
I used Git for version control and regularly pushed my local changes to a private GitHub repository.

\subsection{Ethical statement}
The development of this project did not require human participants, so nobody was harmed during its implementation.

The software that has been developed contributes to an existing blockchain ecosystem. Blockchains have many positive applications, but by their nature, they can facilitate the creation of exploitative markets. Since this software is already widely available, this project will not further this exploitation. Additionally, permissioned blockchains alleviate some of these harms as they are deployed in more controlled environments, and do not require energy-intensive proof of work mechanisms.